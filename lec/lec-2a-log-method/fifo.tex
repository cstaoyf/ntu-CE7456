\include{./def/yf-formatting}
\include{./def/yf-def}

\title{}
\author{}
\date{}


\def\InvS{\textrm{InvS}}
\def\deg{\textrm{deg}}

\def\bD{\mathbb{D}}
\def\bQ{\mathbb{Q}}

% \def\A{\mathcal{A}}
\def\B{\mathcal{B}}
\def\C{\mathcal{C}}
\def\Cb{\mathbb{C}}
\def\E{\mathcal{E}}
\def\F{\mathcal{F}}
\def\G{\mathcal{G}}
\def\I{\mathcal{I}}
\def\L{\mathcal{L}}
\def\R{\mathcal{R}}
\def\T{\mathcal{T}}
%\def\U{\mathcal{U}}
%\def\X{\mathcal{X}}

\def\ans{\textsc{Ans}}

\def\extraspacing{\vspace{3mm} \noindent}
\def\vgap{\vspace{3mm}}
\def\vslit{\vspace{0.5mm}}

\begin{document}

% \begin{center}
%     {\bf \large Lecture Notes} \\
%     {\bf \large Approximate Nearest Neighbor Search 1 : Proximity Graphs} \\[5mm]
%     {\large Yufei Tao} \\[10mm]
% \end{center}

\boxminipg{\linewidth}{
    \begin{center}
        \vspace{3mm}
    {\Large
    (CE7456 Lecture Notes 6) FIFO Indexes} \\[2mm]
    {\large Yufei Tao}
        \vspace{3mm}
    \end{center}
}


In the previous lecture, we talked about the {\em logarithmic method} for turning a static structure into a semi-dynamic one. Today, we will see how to use it to make a static structure fully dynamic when insertions and deletions obey the {\em first in first out} (FIFO) order.


\section{Decomposable Problems under FIFO Updates} \label{sec:decomp}

%This section will formalize the class of problems to be investigated.

Let $\bD$ be a (possibly infinite) set called the {\em data domain}, whose members are called {\em data elements}. Let $\bQ$ be a (possibly infinite) set called the {\em query domain}, whose members are called {\em queries}. Over a finite $S \subseteq \bD$, each query $q \in \bQ$ returns an {\em answer}, represented as $\ans_q(S)$. In a {\em problem} characterized by $(\bD, \bQ)$, the goal is to store a given set $S \subseteq \bD$ --- where $S$ is called the {\em dataset} --- in a data structure that allows us to compute $\ans_q(S)$ efficiently for any $q \in \bQ$. The problem is {\em decomposable} if, for any disjoint sets $S_1, S_2 \subseteq \mathbb{D}$ and any query $q \in \mathbb{Q}$, it is possible to derive $\ans_q(S_1 \cup S_2)$ from $\ans_q(S_1)$ and $ \ans_q(S_2)$ in constant time.

\vgap

We assume that $S$ is initially empty and can be updated by two operations:
\myitems{
    \item Insertion$(e)$, which adds a new element $e$ to $S$;
    \item Deletion, which removes from $S$ the ``oldest'' element in $S$ --- namely, the element that was inserted the longest time ago.
}
The above is the {\em FIFO update model}. For convenience, we say that the $i$-th ($i \ge 1$) insertion happens at {\em timestamp $i$}. An element $e$ is older than another element $e'$ if the insertion time of $e$ is smaller than that of $e'$.

\vgap

%However, as the size of $S$ can now fluctuate (i.e., $|S|$ may go up and down), we must exercise care in defining what it means by ``amortized update cost $U(n)$'', where $U: \real_{\ge 0} \rightarrow \real_{\ge 0}$ is a function.

Our goal is to maintain a data structure on $S$ that (i) has small space and query time, and (ii) can be updated with a small ``amortized cost''. Specifically, given a function $U: \real_{\ge 0} \rightarrow \real_{\ge 0}$, we say that a structure can be updated in $U(n)$ {\em amortized time} if the following is true after {\em every} update:

\minipg{0.9\linewidth}{
    Let $T$ be the total number of insertions received. Suppose that the size of $S$ was $N_i$ ($i \in [1, T]$) when the $i$-th element was inserted. Then, the total cost of performing all the updates (including insertions and deletions) so far is bounded by
    \myeqn{
        \sum_{i=1}^T U(N_i). \label{eqn:amortized}
    }
}

% \section{Non-Decreasing Functions}
%
% A function $f: \real_{>0} \rightarrow \real_{>0}$ is said to grow {\em at least linearly} if $\fr{f(x)}{x}$ is a non-decreasing for $x > 0$.
%
% \begin{lemma}
%     If $f: \real_{>0} \rightarrow \real_{>0}$ grows at least linearly, then $f(a) + f(b) \le f(a+b)$ holds for any $a > 0$ and $b > 0$.
% \end{lemma}
%
% \begin{proof}
%     As $f(x)$ grows at least linearly, we have:
%     \myeqn{
%         \fr{f(a)}{a} &\le& \fr{f(a+b)}{a+b} \nn \\
%         \fr{f(b)}{b} &\le& \fr{f(a+b)}{a+b}. \nn
%     }
%     Combining the above yields:
%     \myeqn{
%         f(a) + f(b) \le \Big(\fr{a}{a+b} + \fr{b}{a+b} \Big) f(a+b)
%         = f(a+b). \nn
%     }
% \end{proof}



\section{The Logarithmic Method for the FIFO Model} \label{sec:log}

We will prove:

\begin{theorem} \label{thm:log:main}
    Consider a decomposable problem for which there is a static structure $\Upsilon$ that
    \myitems{
        \item stores $n$ elements in $F(n)$ space, where $F(.)$ grows at least linearly;
        \item can be constructed in $n \cdot U(n)$ time where $U(.)$ satisfies $U(2n) = O(U(n))$ for any $n \ge 1$;
        \item answers a query in $Q(n)$ time (plus, if necessary, a cost linear to the number of reported elements).
    }
    Set $h = \lc \log_2 n \rc$. Under the FIFO update model, there is a structure that
    \myitems{
        \item stores $n$ elements in $F(n)$ space;
        \item supports an update (an insertion or a deletion) in $U(n) \cdot O(\log n)$ amortized time;
        \item answers a query in $Q(n) \cdot O(\log n)$ time (plus, if necessary, a cost linear to the number of reported elements).
    }

\end{theorem}

\subsection{Structure} \label{sec:log:str}

Let $S$ be the input set of elements. At all times, we partition $S$ into a {\em sequence} of disjoint subsets
\myeqn{
    D_0, D_1, ..., D_{h^-}, I_{h^+}, I_{h^+-1}, ..., I_0  \label{eqn:seq}
}
satisfying the following conditions:
\myitems{
    \item {\bf C1:} $h^-$ and $h^+$ are integers in $\set{-1, 0, 1, 2, ...}$ satisfying $h^+ \le h^-$ (note: if $h^+ = -1$, then the subsets $I_{h^+}, I_{h^+-1}, ..., I_0$ do not exist; similarly, if $h^- = -1$, the subsets $D_0, D_1, ..., D_{h^-}$ do not exist).
    \item {\bf C2:} If $h^+ \ge 0$, then $|I_{h^+}| = 2^{h^+}$; for each $i \in [0, h^+ - 1]$, $|I_i|$ is either 0 or $2^i$.
    \item {\bf C3:}Iif $h^- \ge 0$, then $|D_{h^-}| = 2^{h^-}$; for each $i \in [0, h^-]$, $|D_i|$ is either 0 or $2^i$.
    \item {\bf C4:} If an element $e$ is older than another element $e'$, then the subset containing $e$ must precede (in the sequence shown in \eqref{eqn:seq}) the one containing $e'$.
}

%Note that the first bullet implies that $h^- \ge 0$ as long as $S$ is non-empty.

%\vgap

Create a structure of $\Upsilon$ (as is supplied to Theorem~\ref{thm:log:main}) on each subset. The set of structures --- denoted as $\Upsilon^D_0, \Upsilon^D_1, ..., \Upsilon^D_{h^-}, \Upsilon^I_{h^+}, \Upsilon^I_{h^+-1}, ..., \Upsilon^I_0$ following the ordering in \eqref{eqn:seq} --- together constitute our structure. The space usage is bounded by $F(n)$ because $F(.)$ grows at least linearly (proof left to you).


\subsection{Query} \label{sec:log:qry}

To answer a query $q$, we simply search all the $h^+ + h^-$ structures. As the query is decomposable, we can obtain the answer on $S$ from the answers on the $h^+ + h^-$ structures in $O(h^+ + h^-) = O(\log n)$ time. The overall query time, excluding the cost of outputting the result, is
\myeqn{
    O(\log n) + \sum_{i=0}^{h^+} Q(2^i) + \sum_{i=0}^{h^-} Q(2^i) = Q(n) \cdot O(\log n). \nn
}

\subsection{Insertion} \label{sec:log:ins}

To insert an element $e_\mit{new}$, we identify the smallest $i \in [0, h^+]$ satisfying
\myeqn{
    |I_i| & = & 0 \nn
}
or declare that such an $i$ does not exist.
\myitems{
    \item If $i$ exists, destroy $\Upsilon^I_0, \Upsilon^I_1, ..., \Upsilon^I_{i-1}$ and move all the elements in $I_0, I_1, ..., I_{i-1}$, together with $e_\mit{new}$, into $I_i$. After this, $I_0, I_1, ..., I_{i-1}$ become empty. Build $\Upsilon^I_i$ on $I_i$, which takes $2^i \cdot U(2^i)$ time. We amortize this over the $2^i$ elements in $I_i$, each of which bears a cost of $U(2^i)$.

    \item Otherwise, destroy $\Upsilon^I_0, \Upsilon^I_1, ..., \Upsilon^I_{h^+}$ and move all the elements in $I_0, I_1, ..., I_{h^+}$, together with $e_\mit{new}$, into $I_{h^++1}$. After this, $I_0, I_1, ..., I_{h^+}$ become empty. Build $\Upsilon_{h^++1}$ on $I_{h^++1}$, which takes $2^{h^++1} \cdot U(2^{h^++1})$ time. We amortize this over the $2^{h^++1}$ elements in $I_{h^++1}$, each of which bears a cost of $U(2^{h^++1})$.

    \vgap

    The value of $h^+$ then increases by 1.
    Importantly, at this moment, $h^+$ may be greater than $h^-$. In that case, it must hold that $h^+ = h^- + 1$ (think: why?); we
    \myitems{
        \item rename $I_{h^+}$ to $D_{h^- + 1}$ and accordingly $\Upsilon^I_{h^+}$ to $\Upsilon^D_{h^- + 1}$;
        \item increase $h^-$ by 1 and reset $h^+$ to $-1$.
    }
}

\noindent {\bf Remark.} We insert a remark here that will be useful for analyzing the amortized update cost. Whenever a new subset $I_i$ --- for some $i \ge 0$ --- is created, every element in $I_i$ is amortized a cost of $U(|I_i|)$.

\subsection{Deletion} \label{sec:log:del}

To delete the {\em oldest} $e_\mit{old}$, we identify the smallest $i \in [0, h^-]$ satisfying
\myeqn{
    |I_i| & = & 2^i. \nn
}
Such an $i$ definitely exists (think: why?), and $I_i$ must be the subset containing $e_\mit{old}$.

\vgap

We destroy $\Upsilon^D_i$ and partition $D_i \setminus \set{e_\mit{old}}$ into $D_0, D_1, ..., D_{i-1}$ such that
\myitems{
    \item $D_j$ contains $2^j$ elements for every $j \in [0, i-1]$;

    \item if an element $e \in D_i$ is older than another element $e' \in D_i$, the subsets $D_j$ and $D_{j'}$ containing $e$ and $e'$, respectively, must satisfy $j \le j'$.
}
For each $j \in [0, i-1]$, build $\Upsilon^D_j$ on $D_j$. The total cost of building $\Upsilon^D_0, \Upsilon^D_1, ..., \Upsilon^D_{i-1}$ is bounded by
\myeqn{
    \sum_{j=0}^{i-1} 2^j \cdot U(2^j) \le U(2^i) \cdot \sum_{j=0}^{i-1} 2^j < U(2^i) \cdot 2^i. \nn
}
We amortize this over the $2^i$ elements that were in $I_i$; each element thus bears a cost of $U(2^i)$.

\vgap

Decrease $h^-$ by 1. At this moment, $h^-$ may be lower than $h^+$. In that case, it must hold that $h^- = h^+ - 1$; we
\myitems{
    \item rename $I_{h^+}$ to $D_{h^- + 1}$ and accordingly $\Upsilon^I_{h^+}$ to $\Upsilon^D_{h^- + 1}$;
    \item increase $h^-$ by 1 and set $h^+$ to the highest $j \in [0, h^+-1]$ such that $D_j$ is non-empty (if no such $j$ exists, set $h^+ = -1$).
}

\noindent {\bf Remark.} We insert a remark here that will be useful for analyzing the amortized update cost. Whenever a subset $D_i$ --- for some $i \ge 0$ --- is destroyed, every element in $D_i$ is amortized a cost of $U(|D_i|)$.


\subsection{Amortized Update Cost}

Let us focus on an arbitrary element $e$. Assume that the size of $S$ is $N_e$ when $e$ is inserted. Our objective is to show that the total update cost can be amortized over all the elements ever inserted such that $e$ bears a cost of at most $U(2N_e) \cdot O(\log N_e)$. Because $U(2 N_e) = O(U(N_e))$ --- as stated in Theorem~\ref{thm:log:main} --- we have
\myeqn{
    U(2N_e) \cdot O(\log N_e)
    =
    O(U(N_e)) \cdot O(\log N_e)
    =
    U(N_e) \cdot O(\log N_e). \nn
}

%\vgap

We will prove a crucial fact:

\begin{lemma} \label{lmm:fact}
    After each update, the subset --- which may be an $I_i$ or a $D_i$ --- containing $e$ must have a size at most $2N_e$.
\end{lemma}

The lemma implies our claim --- $e$ is amortized at most a cost of $U(2 N_e) \cdot O(\log N_e)$ --- because
\myitems{
    \item every time $e$ is charged, it bears a cost of $U(2N_e)$ (see the remarks in Sections~\ref{sec:log:ins} and \ref{sec:log:del});
    \item $e$ can be charged $O(\log N_e)$ times as
    every $I_i$ or $D_i$ containing $e$ satisfies $2^i \le 2N_e$, indicating $i \le 1 + \log_2 N_e$.
}

\extraspacing {\bf Proof of Lemma~\ref{lmm:fact}.} We say that an update {\em moves $e$ into} a subset $I_i$ (for some $i \ge 0$) (i) $e \notin I_i$ before the update but (ii) $e \in I_i$ after the update. Similarly, we say that an update {\em moves $e$ into} a subset $D_i$ (for some $i \ge 0$) (i) $e \notin D_i$ before the update but (ii) $e \in D_i$ after the update.

\vgap

There are three scenarios where $e$ is can be moved into a new subset:
\myenums{
    \item an insertion moves $e$ into $I_i$ for some $i \ge 0$;
    \item an insertion moves $e$ into $D_{h^-}$;
    \item a deletion moves $e$ into $D_{h^-}$;
    \item a deletion moves $e$ into $D_i$ for some $i \ge 0$.
}
We will prove the lemma by analyzing each case in turn. Hence, we will refer to each $I_i$ (resp., $D_i$) as an {\em $I$-subset} (resp., {\em $D$-subset}).

\myitems{
    \item {\bf Case 1:} In this case, all the elements in every $D$-subset must be older than $e$. Hence, $|D_{h^-}| \le N_e$ because at most $N_e$ elements can be older than $e$. Hence, $|I_i| \le |I_{h^+}| \le |D_{h^-}| \le N_e$.

    \item {\bf Case 2:} In this case, before the insertion, we must have:
    \myitems{
        \item $h^+ = h^-$ (by how our insertion algorithm works);
        \item $|I_{h^+}| \le |D_{h^-}| \le N_e$ (by the same argument used in Case 1).
    }
    The insertion first creates $I_{h^+ + 1}$ --- whose size is $2|I_{h^+}| \le 2N_e$ --- renames $I_{h^+ + 1}$ to $D_{h^- + 1}$, increases $h^-$ by 1, and then sets $h^+ = -1$. The final $D_{h^-}$ is the $I_{h^+ + 1}$ before the renaming and, hence, has a size at most $2N_e$.

    \item {\bf Case 3:} In this case, before the deletion, we must have:
    \myitems{
        \item $e \in I_{h^+}$ and $h^+ = h^-$ (by how our deletion algorithm works);
        \item $|I_{h^+}| \le |D_{h^-}| \le N_e$ (by the same argument used in Case 1).
    }
    The deletion first destroys $D_{h^-}$, renames $I_{h^+}$ to $D_{h^-}$, and then decreases $h^+$ (the value of $h^-$ remains unchanged). The final $D_{h^-}$ is the $I_{h^+}$ before the renaming and, hence, has a size at most $N_e$.

    \item {\bf Case 4:} This case can occur only after Case 3. In fact, after Case 3, $e$ can only move to subsets of smaller sizes. Hence, $|D_i|$ must be bounded by $N_e$.
}

\section{Remark}

The technique in Section~\ref{sec:log} was developed in \cite{st11c}.


\bibliographystyle{plain}
\bibliography{ref}

\end{document}
