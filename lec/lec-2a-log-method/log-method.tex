\include{./def/yf-formatting}
\include{./def/yf-def}

\title{}
\author{}
\date{}


\def\InvS{\textrm{InvS}}
\def\deg{\textrm{deg}}

\def\bD{\mathbb{D}}
\def\bQ{\mathbb{Q}}

% \def\A{\mathcal{A}}
\def\B{\mathcal{B}}
\def\C{\mathcal{C}}
\def\Cb{\mathbb{C}}
\def\E{\mathcal{E}}
\def\F{\mathcal{F}}
\def\G{\mathcal{G}}
\def\I{\mathcal{I}}
\def\L{\mathcal{L}}
\def\R{\mathcal{R}}
\def\T{\mathcal{T}}
%\def\U{\mathcal{U}}
%\def\X{\mathcal{X}}

\def\ans{\textsc{Ans}}

\def\extraspacing{\vspace{3mm} \noindent}
\def\vgap{\vspace{3mm}}
\def\vslit{\vspace{0.5mm}}

\begin{document}

% \begin{center}
%     {\bf \large Lecture Notes} \\
%     {\bf \large Approximate Nearest Neighbor Search 1 : Proximity Graphs} \\[5mm]
%     {\large Yufei Tao} \\[10mm]
% \end{center}

\boxminipg{\linewidth}{
    \begin{center}
        \vspace{3mm}
    {\Large
    (CE7456 Lecture Notes 5) The Logarithmic Method} \\[2mm]
    {\large Yufei Tao}
        \vspace{3mm}
    \end{center}
}


%\chapter{The Logarithmic Method} \label{lec:rebuild}

A data structure is said to be
\myitems{
    \item {\em static} if it does not support any updates;
    \item {\em semi-dynamic} if it supports only insertions;
    \item {\em fully-dynamic} if it supports both insertions and deletions.
}
Today, we will learn a generic technique --- called the {\em logarithmic method} --- that can turn a static structure into a semi-dynamic one.

%We will use the kd-tree (Section~\ref{sec:pt:kd}) to illustrate the technique. Indeed, the kd-tree serves as an excellent example because it may seem exceedingly difficult to modify the structure for updates. For example, the first cut in a kd-tree --- let us recall --- ought to be a vertical line that divides the point set as evenly as possible. Unfortunately, even a single point insertion would throw off the balance and thus destroy the whole tree. It may be surprising to you that later we will make the kd-tree semi-dynamic without changing the structure at all.


\section{Decomposable Problems} \label{sec:rebuild:decomp}

%This section will formalize the class of problems to be investigated.

Let $\bD$ be a (possibly infinite) set called the {\em data domain}, whose members are called {\em data elements}. Let $\bQ$ be a (possibly infinite) set called the {\em query domain}, whose members are called {\em queries}. Over a finite $S \subseteq \bD$, each query $q \in \bQ$ returns an {\em answer}, represented as $\ans_q(S)$. In a {\em problem} characterized by $(\bD, \bQ)$, the goal is to store a given set $S \subseteq \bD$ --- where $S$ is called the {\em dataset} --- in a data structure that allows us to compute $\ans_q(S)$ efficiently for any $q \in \bQ$.

\vgap

A problem characterized by $(\bD, \bQ)$ is {\em decomposable} if, for any disjoint sets $S_1, S_2 \subseteq \mathbb{D}$ and any query $q \in \mathbb{Q}$, it is possible to derive $\ans_q(S_1 \cup S_2)$ from $\ans_q(S_1)$ and $ \ans_q(S_2)$ in constant time.

\vgap

Consider, for example, 1D range reporting, where $S$ is a set of integers, a query $q$ is an interval, and $\ans_q(S)$ is $S \cap q$, i.e., the set of integers in $S$ covered by $q$. As another example, in 1D range counting, the meanings of $S$ and $q$ are identical to those  in 1D range reporting, but $\ans_q(S)$ is $|S \cap q|$, i.e., how many integers of $S$ are covered by $q$. Both problems are decomposable.

\section{Non-Decreasing Functions}

A function $f: \real_{>0} \rightarrow \real_{>0}$ is said to grow {\em at least linearly} if $\fr{f(x)}{x}$ is a non-decreasing for $x > 0$.

\begin{lemma}
    If $f: \real_{>0} \rightarrow \real_{>0}$ grows at least linearly, then $f(a) + f(b) \le f(a+b)$ holds for any $a > 0$ and $b > 0$.
\end{lemma}

\begin{proof}
    As $f(x)$ grows at least linearly, we have:
    \myeqn{
        \fr{f(a)}{a} &\le& \fr{f(a+b)}{a+b} \nn \\
        \fr{f(b)}{b} &\le& \fr{f(a+b)}{a+b}. \nn
    }
    Combining the above yields:
    \myeqn{
        f(a) + f(b) \le \Big(\fr{a}{a+b} + \fr{b}{a+b} \Big) f(a+b)
        = f(a+b). \nn
    }
\end{proof}



\section{The Logarithmic Method} \label{sec:rebuild:log}

We will prove:

\begin{theorem} \label{thm:log:main}
    Consider a decomposable problem for which there is a static structure $\Upsilon$ that
    \myitems{
        \item stores $n$ elements in $F(n)$ space, where $F(.)$ grows at least linearly;
        \item can be constructed in $n \cdot U(n)$ time;
        \item answers a query in $Q(n)$ time (plus, if necessary, a cost linear to the number of reported elements).
    }
    Set $h = \lc \log_2 n \rc$. There is a semi-dynamic structure $\Upsilon'$ that
    \myitems{
        \item stores $n$ elements in $F(n)$ space;
        \item supports an insertion in $U(n) \cdot O(\log n)$ amortized time;
        \item answers a query in $Q(n) \cdot O(\log n)$ time (plus, if necessary, a cost linear to the number of reported elements)
    }


    %If in addition $\Upsilon$ also supports a deletion in at most $U_\mit{del}(n)$ worst-case time, then $\Upsilon'$ is a fully dynamic structure that supports a deletion in $O(\log n) + U_\mit{del}(n)$ worst-case time, and retains all the above properties.
\end{theorem}
%
% \vgap
%
% Before delving into the proof, let us first see an application. Suppose that we have a structure that can be constructed in $O(n \log n)$ time and answers a query in $O(\sqrt{n})$ time. Therefore:
% \myeqn{
%     F(n) &=& O(n) \nn \\
%     U(n) &=& O(\log n) \nn \\
%     Q(n) &=& O(\sqrt{n}). \nn
% }
% Theorem~\ref{thm:log:main} immediately gives a semi-dynamic structure that uses
% \myeqn{
%     \sum_{i=0}^{\lc \log_2 n \rc} O(2^i) &=& O(n) \nn
% }
% space, supports an insertion in
% \myeqn{
%     \sum_{i=0}^{\lc \log_2 n \rc} O\left(\log 2^i\right) &=& O(\log^2 n) \nn
% }
% amortized time, and answers a query in
% \myeqn{
%     \sum_{i=0}^{\lc \log_2 n \rc} O\left(\sqrt{2^i}\right) &=& O(\sqrt{n}) \nn
% }
% time.


\subsection{Structure} \label{sec:rebuild:log:str}

Let $S$ be the input set of elements. Set $n = |S|$ and $h = \lc \log_2 n \rc$. At all times, we partition $S$ arbitrarily into disjoint subsets $S_0, S_1, ..., S_h$ (some of which may be empty) satisfying:
\myeqn{
    |S_i| &=& \textrm{either 0 or $2^i$}. \label{eqn:rebuild:log:size}
}
(Think: why is such partitioning always possible?) Create a structure of $\Upsilon$ (as is supplied to Theorem~\ref{thm:log:main}) on each subset; denote by $\Upsilon_i$ the structure on $S_i$. Then, $\Upsilon_1, \Upsilon_2, ..., \Upsilon_h$ together constitute our semi-dynamic structure.

\vgap

The space usage is bounded by $\sum_{i=0}^h F(|S_i|)$, which is at most $F(\sum_{i=0}^h |S_i|) = F(n)$ because $F(.)$ grows at least linearly.


\subsection{Query} \label{sec:rebuild:log:qry}

To answer a query $q$, we simply search all of $\Upsilon_1, ..., \Upsilon_h$. As the query is decomposable, we can obtain the answer on $S$ from the answers on $S_1, ..., S_h$ in $O(h)$ time. The overall query time is
\myeqn{
    O(h) + \sum_{i=0}^h Q(2^i) = Q(n) \cdot O(\log n). \nn
}

\subsection{Insertion} \label{sec:rebuild:log:ins}

To insert an element $e_\mit{new}$, we identify the smallest $i \in [0, h]$ satisfying
\myeqn{
    |S_i| & = & 0 \nn
}
or declare that such an $i$ does not exist.
\myitems{
    \item If $i$ exists, destroy $\Upsilon_0, \Upsilon_1, ..., \Upsilon_{i-1}$ and move all the elements in $S_0, S_1, ..., S_{i-1}$, together with $e_\mit{new}$, into $S_i$. (Think: why doesn't this violate \eqref{eqn:rebuild:log:size}?) After this, $S_0, S_1, ..., S_{i-1}$ become empty. Rebuild $\Upsilon_i$ on the $S_i$ from scratch.

    \item Otherwise, destroy $\Upsilon_0, \Upsilon_1, ..., \Upsilon_h$ and move all the elements in $S_0, S_1, ..., S_h$, together with $e_\mit{new}$, into $S_{h+1}$. After this, $S_0, S_1, ..., S_h$ become empty. Build $\Upsilon_{h+1}$ on $S_{h+1}$ from scratch. The value of $h$ then increases by 1.
}

Next, we analyze the insertion cost with a charging argument. The reconstruction of $\Upsilon_i$ ($i \ge 0$) requires
\myeqn{
    |S_i| \cdot U(|S_i|) &=& 2^i \cdot U(2^i) \label{eqn:rebuild:log:rebuildcost}
}
time. We charge this over the $2^i$ elements in $S_i$, each of which bears a cost of $U(2^i)$. As an element can only move from an $S_i$ to an $S_j$ with $i < j$, each element can be charged a total cost of at most
\myeqn{
        \sum_{i=0}^h U(2^i) = U(n) \cdot O(\log n). \nn
}

\section{Remark}

The logarithmic method was developed by Bentley and Saxe \cite{bs80}.

%There are standard {\em de-amortization} techniques (see \cite{o87}) that convert a structure with small amortized update time into a structure achieving a small time bound on {\em every} update. By applying those techniques, we can turn our modified kd-tree into a structure that ensures $O(\log^2 n)$ time on every insertion.


\bibliographystyle{plain}
\bibliography{ref}

\end{document}
